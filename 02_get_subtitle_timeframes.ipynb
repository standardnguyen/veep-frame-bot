{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_timestamps_from_sup(sup_file, output_dir):\n",
    "    \"\"\"Extract XML from a SUP file using BDSup2Sub.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Command to extract XML using BDSup2Sub\n",
    "    cmd = [\n",
    "        'java', '-jar', '/home/coof/BDSup2Sub.jar',\n",
    "        sup_file,\n",
    "        '-o', os.path.join(output_dir, 'output.xml'),  # Output XML file\n",
    "    ]\n",
    "    \n",
    "    # Run the command\n",
    "    subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_srt_entry(index, start_time, end_time):\n",
    "    \"\"\"Format timestamps into SRT entry.\"\"\"\n",
    "    return f\"{index}\\n{start_time} --> {end_time}\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifically for srts already\n",
    "\n",
    "\n",
    "def parse_timecode(timecode):\n",
    "    \"\"\"Convert timecode from format 'hh:mm:ss,ms' to 'hh:mm:ss:ff'.\"\"\"\n",
    "    hh, mm, ss_ms = timecode.split(':')\n",
    "    ss, ms = ss_ms.split(',')\n",
    "    ff = int(ms) // 40  # Convert milliseconds to frame count (assuming 25fps)\n",
    "    return f'{hh}:{mm}:{ss}:{ff:02d}'\n",
    "\n",
    "def process_subtitle_file(input_file, output_csv):\n",
    "    with open(input_file, 'r') as infile, open(output_csv, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"Index\", \"Start Time\", \"End Time\", \"Text\"])\n",
    "\n",
    "        lines = infile.readlines()\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "\n",
    "            # Check if the line is a numeric index\n",
    "            if line.isdigit():\n",
    "                index = int(line)  # Capture the subtitle index\n",
    "                i += 1\n",
    "\n",
    "                # The next line should be the timestamp\n",
    "                timestamp_line = lines[i].strip()\n",
    "                start_time, end_time = timestamp_line.split(' --> ')\n",
    "                start_time = parse_timecode(start_time.strip())\n",
    "                end_time = parse_timecode(end_time.strip())\n",
    "                i += 1\n",
    "\n",
    "                # Collect all subtitle text lines until a blank line is encountered\n",
    "                subtitle_text = []\n",
    "                while i < len(lines) and lines[i].strip() != \"\":\n",
    "                    subtitle_text.append(lines[i].strip())\n",
    "                    i += 1\n",
    "\n",
    "                # Write the collected data to the CSV\n",
    "                writer.writerow([index, start_time, end_time, \" \".join(subtitle_text)])\n",
    "\n",
    "            i += 1\n",
    "\n",
    "# # Example usage:\n",
    "# process_subtitle_file('input.txt', 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sup_to_csv(sup_file, output_csv, xml_file):\n",
    "    # Directory to store the extracted XML\n",
    "    output_dir = \"temp\"\n",
    "    \n",
    "    # Step 1: Extract timestamps from the SUP file\n",
    "    extract_timestamps_from_sup(sup_file, output_dir)\n",
    "    \n",
    "    # Step 2: Parse the XML and extract timing information\n",
    "    tree = ET.parse(os.path.join(output_dir, 'output.xml'))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    shutil.copy(os.path.join(output_dir, 'output.xml'), xml_file)\n",
    "    \n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        \n",
    "        # Write the header row\n",
    "        csvwriter.writerow(['Index', 'Start Time', 'End Time'])\n",
    "        \n",
    "        index = 1\n",
    "        \n",
    "        for sub in root.findall('.//Event'):\n",
    "            start_time = sub.get('InTC')\n",
    "            end_time = sub.get('OutTC')\n",
    "            \n",
    "            # Write the row to the CSV file\n",
    "            csvwriter.writerow([index, start_time, end_time])\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subtitle_files(source_dir, destination_dir):\n",
    "    # Define the range of seasons (e.g., Season 1 to Season 7)\n",
    "    seasons = sorted([f\"Season {i}\" for i in range(5, 7)])\n",
    "\n",
    "    # Loop through each season folder\n",
    "    for season in seasons:\n",
    "        season_path = os.path.join(source_dir, season)\n",
    "\n",
    "        # Check if the season directory exists\n",
    "        if not os.path.isdir(season_path):\n",
    "            print(f\"Directory {season_path} does not exist, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Create corresponding destination directory for the season\n",
    "        destination_season_path = os.path.join(destination_dir, season)\n",
    "        os.makedirs(destination_season_path, exist_ok=True)\n",
    "\n",
    "        # Get sorted list of files in the season folder\n",
    "        files = sorted(os.listdir(season_path))\n",
    "\n",
    "        # Process each file in the season folder\n",
    "        for filename in files:\n",
    "            # Look for complete .mkv files\n",
    "            if filename.endswith('.mkv') and not filename.endswith('.mkv.part'):\n",
    "\n",
    "                pattern = r\"S\\d{2}E\\d{2} - [^()]+\"\n",
    "\n",
    "                match = re.search(pattern, filename)\n",
    "                if match:\n",
    "                    modified_filename = match.group(0)\n",
    "\n",
    "                video_file = os.path.join(season_path, filename)\n",
    "                sup_file = os.path.join(destination_season_path, modified_filename.strip(), \"subtitles.sup\")\n",
    "                csv_file = os.path.join(destination_season_path, modified_filename.strip(), \"subtitles.csv\")\n",
    "                xml_file = os.path.join(destination_season_path, modified_filename.strip(), \"subtitles.xml\")\n",
    "                \n",
    "\n",
    "                # convert_sup_to_csv(sup_file, csv_file, xml_file)\n",
    "                # process_subtitle_file(sup_file, csv_file)\n",
    "                # sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the source and destination directories\n",
    "source_directory = \"./Silicon Valley Raw\"  # Replace with the path to your directory containing seasons\n",
    "destination_directory = \"./Silicon Valley\"\n",
    "\n",
    "# Call the function to burn subtitles\n",
    "process_subtitle_files(source_directory, destination_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
